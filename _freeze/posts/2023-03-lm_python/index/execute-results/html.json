{
  "hash": "baddb1fd9e6664f5ffe04e3e971217b3",
  "result": {
    "markdown": "---\ntitle: \"Model 1 - Linear Regression in Python with Kaggle Data\"\nauthor: \"I. Muliterno\"\ndate: \"2023-03-06\" \ncategories: \n# exemplo de categorias:\n  - \"Machine learning\"\n  - \"Statistics\"\n  - \"Data Science\"\n  - \"Linear Regression\"\n  - \"Python\"\n  - \"Kaggle\"\ntoc: true # isso habilita o sumário ao lado do post\n#image: \"images/logo.png\" # imagem usada na página inicial junto ao post\n#bibliography: \"pacotes.bib\" # arquivo de bibliografia. Pode adicionar mais arquivos!\ndraft: false # enquanto estiver draft: true, o post é um rascunho\nknitr: \n  opts_chunk: \n    message: true\n    warning: false\n    echo: true\n    fig.align: 'center'\nhtml:\n  code-fold: true\njupyter: python3\n---\n\n\nIn our previous post, we discussed different modeling approaches and their applications. Today, we will delve deeper into linear regression, one of the most commonly used modeling techniques in data science. By the end, you will learn when to use linear regression and how to code it from start to finish using a dataset from Kaggle.\n\n## 1. Getting to know Linear Regression\n\nLinear regression is a popular modeling approach used for predicting continuous values. It is a simple yet powerful modeling approach that **works well when the relationship between the predictor and response variable is linear**. It is important to ensure that the assumptions of linear regression are met, including linearity, independence, normality, and equal variance. These assumptions can be tested using various techniques, such as residual plots and statistical tests. Linear regression models are easy to interpret and can be used for both simple and complex problems.\n\nSimple linear regression involves a single independent variable, while multiple linear regression involves two or more independent variables. Examples of where linear regression is commonly used include predicting housing prices, analyzing stock prices, and estimating crop yields.\n\n## 2. Data Cleaning and Visualization\n\nWhen working with real-world data, it is common to encounter missing or erroneous values, inconsistent formatting, and other issues. Data cleaning is the process of detecting and correcting these problems in the data to ensure that it is accurate and reliable for analysis. Visualization, on the other hand, is the process of representing data in a visual format such as graphs, charts, or maps, to help analysts identify patterns and trends.\n\nFor this blog post, we will be using a data set from Kaggle's House Prices: Advanced Regression Techniques competition. This data set contains information on various attributes of residential homes in Ames, Iowa, including their sale prices. The goal of the competition is to build a model that can accurately predict the sale prices of homes based on these attributes.\n\nTo start, we will import the necessary libraries in Python, including Pandas for data manipulation and Matplotlib for visualization. We will then load the data set using the read_csv() function from Pandas.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nNow that we have loaded the data, we can begin the data cleaning process. The first step is to check for missing values in the data. We can use the isnull() function from Pandas to check for missing values and the sum() function to count the number of missing values in each column.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# remove the comment to load the dataset\n#df = pd.read_csv(\"train.csv\")\n\n# Check for missing values\nmissing_values = df.isnull().sum()\nprint(missing_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nId                 0\nMSSubClass         0\nMSZoning           0\nLotFrontage      259\nLotArea            0\n                ... \nMoSold             0\nYrSold             0\nSaleType           0\nSaleCondition      0\nSalePrice          0\nLength: 81, dtype: int64\n```\n:::\n:::\n\n\nThis will give us a count of missing values in each column of the data set. We can then decide how to handle these missing values, depending on the amount of missing data and the nature of the problem. In this case, we will simply drop the columns with more than 50% missing values.\n\nNext, we can check for any duplicate rows in the data set using the duplicated() function from Pandas. If there are any duplicate rows, we can drop them using the drop_duplicates() function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n\n\n# Drop columns with more than 50% missing values\ndf = df.dropna(thresh=len(df)*0.5, axis=1)\n\n# Check for duplicates\nduplicates = df.duplicated()\nprint(duplicates.sum())\n\n# Drop duplicates\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\n```\n:::\n\n```{.python .cell-code}\ndf = df.drop_duplicates()\n```\n:::\n\n\nNow that we have cleaned the data, we can move on to visualization. One common visualization for exploring the relationship between two variables is a scatter plot. We can create a scatter plot of the sale prices and the living area of the homes using Matplotlib.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# Create a histogram of sale prices\nplt.hist(df[\"SalePrice\"], bins=20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(array([ 22., 126., 380., 343., 229., 144.,  86.,  49.,  28.,  23.,  12.,\n         7.,   3.,   1.,   2.,   1.,   2.,   0.,   0.,   2.]), array([ 34900.,  70905., 106910., 142915., 178920., 214925., 250930.,\n       286935., 322940., 358945., 394950., 430955., 466960., 502965.,\n       538970., 574975., 610980., 646985., 682990., 718995., 755000.]), <BarContainer object of 20 artists>)\n```\n:::\n\n```{.python .cell-code}\nplt.xlabel(\"Sale Price ($)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThis will give us a visual representation of the distribution of sale prices in the data set. We can see that the distribution is skewed to the right, with a few homes having very high sale prices.\n\nBy cleaning and visualizing the data, we can gain a better understanding of its properties and identify any potential issues that may need to be addressed before building a linear regression model.\n\n## 3. Building a Linear Regression Model\n\nNow that we have cleaned and visualized the data, we can start building a linear regression model to predict the sale prices of homes based on their attributes. Linear regression is a statistical technique that is commonly used for predicting a numeric value based on one or more input variables. In this case, we will use the input variables in the data set to predict the sale price of each home.\n\nTo start, we will split the data set into a training set and a validation set using the train_test_split() function from Scikit-learn. The training set will be used to train the model, while the validation set will be used to evaluate the model's performance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data set into training and validation sets\ntrain, val = train_test_split(df, test_size=0.2, random_state=42)\n```\n:::\n\n\nNext, we will select the input variables that we want to use in the model. In this case, we will use the living area, number of bedrooms, and number of bathrooms as input variables.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# Select the input variables\nX_train = train[[\"GrLivArea\", \"BedroomAbvGr\", \"FullBath\"]]\ny_train = train[\"SalePrice\"]\n\nX_val = val[[\"GrLivArea\", \"BedroomAbvGr\", \"FullBath\"]]\ny_val = val[\"SalePrice\"]\n```\n:::\n\n\nWe can then build a linear regression model using the LinearRegression() function from Scikit-learn. We can use it to predict the sale prices of homes in the validation set using the predict() function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n\nfrom sklearn.linear_model import LinearRegression\n\n# Build the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict the sale prices of homes in the validation set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinearRegression()\n```\n:::\n\n```{.python .cell-code}\ny_pred = model.predict(X_val)\n```\n:::\n\n\nTo evaluate the performance of the model, we can calculate the mean squared error (MSE) and the coefficient of determination (R-squared) between the predicted sale prices and the actual sale prices in the validation set using the mean_squared_error() and r2_score() functions from Scikit-learn.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Calculate the mean squared error and R-squared\nmse = mean_squared_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\nprint(\"MSE:\", mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMSE: 2806426667.247853\n```\n:::\n\n```{.python .cell-code}\nprint(\"R-squared:\", r2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR-squared: 0.6341189942328371\n```\n:::\n:::\n\n\nA low mean squared error and a high coefficient of determination indicate that the model is accurately predicting the sale prices of homes based on their attributes.\n\nBy building a linear regression model, we can use the input variables in the data set to predict the sale prices of homes with a high degree of accuracy. This information can be useful for real estate professionals, home buyers, and sellers looking to estimate the value of a residential property.\n\n## Summary\n\nIn this post, we have explored the process of using linear regression to predict the sale prices of homes based on their attributes. We started by cleaning and visualizing the data to gain insights into the relationships between the input variables and the sale prices. We then built a linear regression model using the Scikit-learn library and evaluated its performance using the mean squared error and coefficient of determination.\n\nBy following this process, we can make accurate predictions about the sale prices of homes based on their attributes. This information can be valuable for a variety of applications, including real estate valuation, mortgage underwriting, and investment analysis.\n\nAs with any predictive model, it is important to continually evaluate and refine the model over time to ensure that it is accurately predicting the outcome of interest. With continued effort, we can refine our understanding of the relationship between the input variables and the sale prices of homes, and improve the accuracy of our predictions.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}